[Main](../README.md)
---

# Docker Containerization Lesson Plan

## 1. Container Fundamentals

### Useful Information
Containers are lightweight, standalone executable packages that include everything needed to run software: code, runtime, system tools, system libraries, and settings. Unlike VMs, containers share the host system's kernel but run in isolated user spaces.

**Key Concepts:**
- **Isolation**: Each container runs in its own isolated environment
- **Portability**: Containers can run consistently across different environments
- **Efficiency**: Less overhead compared to virtual machines
- **Density**: Multiple containers can run on a single host

### Practice Tasks

#### Task 1: Understanding Container Isolation
```bash
# Run two different containers and observe isolation
docker run -d --name web1 nginx:alpine
docker run -d --name web2 nginx:alpine

# Check running processes in each container
docker exec web1 ps aux
docker exec web2 ps aux

# Create a file in one container and verify it doesn't exist in the other
docker exec web1 touch /tmp/container1-file
docker exec web2 ls /tmp/  # Should not show container1-file
```

**Explanation:**
- `docker run -d` runs a container in detached mode
- `--name` assigns a meaningful name to the container
- `docker exec` executes commands inside a running container
- Each container has its own filesystem namespace

#### Task 2: Port Mapping and Network Isolation
```bash
# Run containers with different port mappings
docker run -d --name web-app1 -p 8080:80 nginx:alpine
docker run -d --name web-app2 -p 8081:80 nginx:alpine

# Test both applications
curl http://localhost:8080
curl http://localhost:8081

# Check network configuration
docker exec web-app1 ip addr show
docker exec web-app2 ip addr show
```

## 2. Docker Essentials

### Useful Information
Docker uses a client-server architecture with:
- **Docker Daemon**: Background service managing containers
- **Docker Client**: Command-line interface
- **Docker Images**: Read-only templates used to create containers
- **Dockerfile**: Script containing instructions to build images

### Practice Tasks

#### Task 1: Basic Docker Operations
```bash
# Pull an image from Docker Hub
docker pull ubuntu:20.04

# Run an interactive container
docker run -it --name my-ubuntu ubuntu:20.04 /bin/bash
# Inside container: run some commands, then exit

# List all containers (including stopped ones)
docker ps -a

# Start, stop, and remove containers
docker stop my-ubuntu
docker start my-ubuntu
docker rm my-ubuntu
```

**Explanation:**
- `docker pull` downloads images from registry
- `-it` flags enable interactive terminal session
- `docker ps -a` shows all containers
- `docker rm` removes containers (must be stopped first)

#### Task 2: Building Custom Images
Create a file named `Dockerfile`:
```dockerfile
FROM nginx:alpine
COPY index.html /usr/share/nginx/html/
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

Create `index.html`:
```html
<!DOCTYPE html>
<html>
<head>
    <title>My Custom App</title>
</head>
<body>
    <h1>Hello from Docker!</h1>
</body>
</html>
```

Build and run:
```bash
docker build -t my-custom-app .
docker run -d -p 8080:80 --name my-app my-custom-app
curl http://localhost:8080
```

## Docker Network - Deep Dive

### Useful Information
Docker provides several network drivers that determine how containers communicate with each other and the outside world.

**Network Drivers:**
- **bridge**: Default network driver for standalone containers
- **host**: Remove network isolation between container and host
- **overlay**: Connect multiple Docker daemons (Swarm mode)
- **macvlan**: Assign MAC addresses to containers
- **none**: Disable all networking

### Practice Tasks

#### Task 1: Exploring Default Bridge Network
```bash
# List all networks
docker network ls

# Inspect default bridge network
docker network inspect bridge

# Run containers on default bridge
docker run -d --name web1 nginx:alpine
docker run -d --name web2 nginx:alpine

# Test connectivity between containers
docker exec web1 ping web2  # This will FAIL - containers can't resolve each other by name
docker exec web1 ping <web2_ip_address>  # Use actual IP from docker inspect

# Check network namespace
docker exec web1 ip addr show eth0
docker exec web2 ip addr show eth0
```

**Explanation:**
- Default bridge network provides basic isolation
- Containers can communicate via IP but not by container name
- Each container gets its own network namespace

#### Task 2: Creating Custom Bridge Network
```bash
# Create a custom bridge network
docker network create --driver bridge my-app-network

# Run containers on custom network
docker run -d --name app1 --network my-app-network nginx:alpine
docker run -d --name app2 --network my-app-network nginx:alpine

# Test connectivity - now containers can resolve each other by name!
docker exec app1 ping app2
docker exec app2 ping app1

# Inspect the custom network
docker network inspect my-app-network
```

#### Task 3: Host and None Networks
```bash
# Use host network (shares host's network namespace)
docker run -d --name host-network-app --network host nginx:alpine

# Check that container uses host networking
docker exec host-network-app ip addr show
# Compare with host's network interfaces
ip addr show

# Use none network (completely isolated)
docker run -d --name no-network-app --network none nginx:alpine
docker exec no-network-app ip addr show  # Only loopback interface
```

#### Task 4: Network Aliases and Links
```bash
# Create network with aliases
docker network create backend

# Run services with multiple aliases
docker run -d --name database --network backend \
  --network-alias db --network-alias mysql \
  postgres:13

docker run -d --name api --network backend \
  --network-alias api --network-alias backend-api \
  my-api-image

# Test connectivity using different aliases
docker exec api ping db
docker exec api ping mysql
docker exec api ping database
```

## 2. Docker Volume - Comprehensive Guide

### Useful Information
Docker volumes provide persistent data storage that survives container lifecycle.

**Volume Types:**
- **Named Volumes**: Managed by Docker, stored in Docker area
- **Bind Mounts**: Map host directories to container paths
- **tmpfs Mounts**: Store data in host memory (non-persistent)

### Practice Tasks

#### Task 1: Working with Named Volumes
```bash
# Create a named volume
docker volume create my-data

# Inspect the volume
docker volume inspect my-data

# Use the volume in a container
docker run -d --name db-container \
  -v my-data:/var/lib/postgresql/data \
  postgres:13

# Check data persistence
docker exec db-container psql -U postgres -c "CREATE DATABASE testdb;"
docker stop db-container
docker rm db-container

# Create new container with same volume
docker run -d --name new-db-container \
  -v my-data:/var/lib/postgresql/data \
  postgres:13

# Verify data persistence
docker exec new-db-container psql -U postgres -c "\l"  # Should show testdb
```

#### Task 2: Bind Mounts for Development
```bash
# Create a simple web app directory
mkdir my-webapp
echo "<h1>Hello from Bind Mount!</h1>" > my-webapp/index.html

# Run nginx with bind mount (development scenario)
docker run -d --name dev-nginx \
  -p 8080:80 \
  -v $(pwd)/my-webapp:/usr/share/nginx/html \
  nginx:alpine

# Test the application
curl http://localhost:8080

# Modify the local file and see changes reflected
echo "<h1>Updated Content!</h1>" > my-webapp/index.html
curl http://localhost:8080  # Changes appear immediately

# Clean up
docker stop dev-nginx
docker rm dev-nginx
```

## 3. Docker CMD vs ENTRYPOINT - Complete Guide

### Useful Information
**CMD vs ENTRYPOINT:**
- **ENTRYPOINT**: Sets the default application to run
- **CMD**: Provides default arguments to ENTRYPOINT
- Both can be overridden at runtime

### Practice Tasks

#### Task 1: Understanding CMD
```dockerfile
# Dockerfile with CMD
FROM alpine:latest
CMD ["echo", "Hello from CMD"]
```

**Build and test:**
```bash
docker build -t cmd-demo .
docker run cmd-demo  # Output: Hello from CMD
docker run cmd-demo echo "Overridden!"  # Output: Overridden!
```

#### Task 2: Understanding ENTRYPOINT
```dockerfile
# Dockerfile with ENTRYPOINT
FROM alpine:latest
ENTRYPOINT ["echo"]
```

**Build and test:**
```bash
docker build -t entrypoint-demo .
docker run entrypoint-demo  # Error: missing arguments
docker run entrypoint-demo "Hello from ENTRYPOINT"  # Output: Hello from ENTRYPOINT
```

#### Task 3: CMD and ENTRYPOINT Together
```dockerfile
# Dockerfile with both
FROM alpine:latest
ENTRYPOINT ["echo"]
CMD ["Default message"]
```

**Build and test:**
```bash
docker build -t both-demo .
docker run both-demo  # Output: Default message
docker run both-demo "Custom message"  # Output: Custom message
```

### How to Override CMD and ENTRYPOINT

#### Overriding CMD
```bash
# Dockerfile: CMD ["npm", "start"]
docker run my-app  # Runs: npm start
docker run my-app npm test  # Overrides CMD: runs npm test
```

#### Overriding ENTRYPOINT
```bash
# Dockerfile: ENTRYPOINT ["node", "app.js"]
docker run my-app  # Runs: node app.js
docker run --entrypoint bash my-app  # Overrides ENTRYPOINT: runs bash
docker run --entrypoint node my-app --version  # Runs: node --version
```

#### Complete Override Example
```bash
# Dockerfile has: ENTRYPOINT ["node"] CMD ["app.js"]
docker run my-app  # Runs: node app.js
docker run my-app server.js  # Runs: node server.js
docker run --entrypoint python my-app  # Error: no CMD provided
docker run --entrypoint python my-app --version  # Runs: python --version
```

## 3. Docker Registry

### Useful Information
Docker Registry is a storage and distribution system for Docker images. Docker Hub is the default public registry, but you can also use private registries.

**Key Concepts:**
- **Public Registry**: Docker Hub (public images)
- **Private Registry**: Self-hosted or cloud-based private repositories
- **Image Tagging**: Versioning system for images
- **Image Pushing/Pulling**: Uploading and downloading images

### Practice Tasks

#### Task 1: Working with Docker Hub
```bash
# Tag your custom image for Docker Hub (replace with your username)
docker tag my-custom-app yourusername/my-custom-app:v1.0

# Login to Docker Hub (create account first if needed)
docker login

# Push image to registry
docker push yourusername/my-custom-app:v1.0

# Pull image from different machine or remove local and pull
docker rmi yourusername/my-custom-app:v1.0
docker pull yourusername/my-custom-app:v1.0
```

#### Task 2: Using Private Registry
```bash
# Run local registry (for testing)
docker run -d -p 5000:5000 --name registry registry:2

# Tag and push to local registry
docker tag my-custom-app localhost:5000/my-custom-app

# Push to local registry
docker push localhost:5000/my-custom-app

# Pull from local registry
docker pull localhost:5000/my-custom-app
```

## 4. Linux cgroups and namespaces

### Useful Information
Docker uses Linux kernel features for isolation:

**Namespaces:**
- **PID**: Process isolation
- **NET**: Network isolation
- **MNT**: Filesystem isolation
- **IPC**: Inter-process communication isolation
- **UTS**: Hostname isolation
- **USER**: User ID isolation

**cgroups (Control Groups):**
- Resource limitation (CPU, memory, I/O)
- Prioritization
- Accounting
- Control

### Practice Tasks

#### Task 1: Exploring Namespaces
```bash
# Run container and check namespaces
docker run -d --name namespace-test alpine sleep 3600

# Find container PID
CONTAINER_PID=$(docker inspect --format '{{.State.Pid}}' namespace-test)

# Check different namespaces
ls -la /proc/$CONTAINER_PID/ns/

# Compare with host namespaces
ls -la /proc/$$/ns/
```

#### Task 2: Working with cgroups
```bash
# Run container with resource limits
docker run -d --name limited-container \
  --memory=100m \
  --cpus=0.5 \
  alpine sleep 3600

# Check cgroup configuration
CONTAINER_ID=$(docker inspect --format '{{.Id}}' limited-container)
cat /sys/fs/cgroup/memory/docker/$CONTAINER_ID/memory.limit_in_bytes
cat /sys/fs/cgroup/cpu/docker/$CONTAINER_ID/cpu.cfs_quota_us
```

## Best Practices

### Security Best Practices
```dockerfile
# Use minimal base images
FROM alpine:latest

# Run as non-root user
RUN addgroup -g 1000 appuser && \
    adduser -D -u 1000 -G appuser appuser
USER appuser

# Use specific version tags, not 'latest'
FROM nginx:1.21-alpine

# Scan images for vulnerabilities
# Use docker scan <image-name>
```

### Efficiency Best Practices
```dockerfile
# Use multi-stage builds
FROM node:16 as builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html

# Leverage build cache effectively
COPY package.json package-lock.json ./
RUN npm install
COPY . .
```

## Use Cases

### 1. Microservices Architecture
```bash
# Run multiple services
docker run -d --name database postgres:13
docker run -d --name api-server -p 3000:3000 --link database my-api
docker run -d --name frontend -p 80:80 --link api-server my-frontend
```

### 2. Development Environments
```yaml
# docker-compose.yml
version: '3.8'
services:
  web:
    build: .
    ports:
      - "3000:3000"
    volumes:
      - .:/app
    environment:
      - NODE_ENV=development
  database:
    image: postgres:13
    environment:
      - POSTGRES_DB=myapp
```

## Homework Tasks

### Beginner Level
1. **Docker Installation and Basic Commands**
   - Install Docker on your local machine
   - Run `docker version` to verify installation
   - Pull and run 3 different official images (nginx, redis, postgres)
   - Practice starting, stopping, and removing containers

2. **Basic Dockerfile**
   - Create a simple Python Flask application
   - Write a Dockerfile to containerize the application
   - Build the image and run it as a container
   - Access the application through your browser

### Intermediate Level
3. **Multi-Container Application**
   - Create a web application that uses a database
   - Write Dockerfiles for both application and database
   - Use docker-compose to orchestrate both services
   - Ensure data persistence using volumes

4. **Image Optimization**
   - Take an existing Dockerfile and optimize it for size
   - Implement multi-stage builds
   - Reduce the final image size by at least 50%
   - Document the optimization steps

### Advanced Level
5. **Custom Registry and CI/CD**
   - Set up a private Docker registry
   - Configure automated builds using GitHub Actions
   - Implement image scanning for security vulnerabilities
   - Set up automated deployment

6. **Resource Management**
   - Create containers with specific resource limits
   - Monitor resource usage using `docker stats`
   - Implement health checks in your Dockerfile
   - Test resource exhaustion scenarios

### Bonus Challenge
7. **Security Hardening**
   - Create a Dockerfile that follows all security best practices
   - Implement user namespace mapping
   - Configure read-only root filesystem where possible
   - Use security scanning tools to validate your image

### Submission Requirements
For each homework task, provide:
- All Dockerfiles and configuration files
- Screenshots of running containers
- Explanation of choices and challenges faced
- Performance metrics (image sizes, startup times)


[Main](../README.md)
---